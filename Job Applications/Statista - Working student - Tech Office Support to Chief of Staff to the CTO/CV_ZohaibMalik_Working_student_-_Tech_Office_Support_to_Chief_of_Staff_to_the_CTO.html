<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Malik Zohaib Hassan - Data Engineer Lebenslauf</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'Calibri', sans-serif;
            line-height: 1.4;
            color: #333;
            background: white;
            font-size: 11px;
        }
        
        .container {
            max-width: 210mm;
            margin: 0 auto;
            padding: 15mm;
            background: white;
            min-height: 297mm;
        }
        
        .header {
            text-align: center;
            margin-bottom: 20px;
            border-bottom: 2px solid #0061a8;
            padding-bottom: 15px;
        }
        
        .name {
            font-size: 24px;
            font-weight: bold;
            color: #0061a8;
            margin-bottom: 5px;
        }
        
        .title {
            font-size: 14px;
            color: #4a5568;
            margin-bottom: 10px;
        }
        
        .contact {
            font-size: 10px;
            color: #666;
        }
        
        .section {
            margin-bottom: 18px;
        }
        
        .section-title {
            font-size: 14px;
            font-weight: bold;
            color: #0061a8;
            border-bottom: 1px solid #e2e8f0;
            padding-bottom: 3px;
            margin-bottom: 8px;
            text-transform: uppercase;
        }
        
        .job {
            margin-bottom: 12px;
        }
        
        .job-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 3px;
        }
        
        .job-title {
            font-weight: bold;
            color: #2d3748;
            font-size: 11px;
        }
        
        .job-period {
            font-size: 10px;
            color: #666;
            white-space: nowrap;
        }
        
        .company {
            font-weight: 600;
            color: #4a5568;
            font-size: 10px;
            margin-bottom: 2px;
        }
        
        .location {
            font-size: 10px;
            color: #666;
            margin-bottom: 5px;
        }
        
        .achievements {
            list-style: none;
            margin-left: 0;
        }
        
        .achievements li {
            margin-bottom: 3px;
            padding-left: 12px;
            position: relative;
            font-size: 10px;
        }
        
        .achievements li:before {
            content: "•";
            color: #0061a8;
            font-weight: bold;
            position: absolute;
            left: 0;
        }
        
        .skills-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            font-size: 10px;
        }
        
        .skill-category {
            margin-bottom: 8px;
        }
        
        .skill-category-title {
            font-weight: bold;
            color: #2d3748;
            margin-bottom: 3px;
            font-size: 10px;
        }
        
        .skill-list {
            color: #4a5568;
            line-height: 1.3;
        }
        
        .education-item {
            margin-bottom: 10px;
        }
        
        .degree {
            font-weight: bold;
            color: #2d3748;
            font-size: 11px;
        }
        
        .university {
            color: #4a5568;
            font-size: 10px;
        }
        
        .edu-details {
            font-size: 10px;
            color: #666;
            margin-top: 2px;
        }
        
        .projects-grid {
            display: grid;
            grid-template-columns: 1fr;
            gap: 10px;
        }
        
        .project {
            margin-bottom: 8px;
        }
        
        .project-title {
            font-weight: bold;
            color: #2d3748;
            font-size: 10px;
            margin-bottom: 2px;
        }
        
        .project-tech {
            font-size: 9px;
            color: #666;
            font-style: italic;
            margin-bottom: 3px;
        }
        
        .project-desc {
            font-size: 10px;
            color: #4a5568;
        }
        
        .languages {
            display: flex;
            gap: 20px;
            font-size: 10px;
        }
        
        .certifications {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            font-size: 10px;
        }
        
        .highlight {
            background-color: #f0f8ff;
            padding: 2px 4px;
            border-radius: 2px;
        }
        
        .azure-highlight {
            background-color: #e8f4fd;
            padding: 2px 4px;
            border-radius: 2px;
            font-weight: 600;
        }
        
        @media print {
            body { margin: 0; }
            .container { 
                margin: 0; 
                padding: 10mm;
                max-width: none;
            }
            .download-btn { display: none !important; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="name">MALIK ZOHAIB HASSAN</div>
            <div class="title">Junior Data Engineer - Azure Cloud & ETL Pipelines</div>
            <div class="contact">
                zohaibmalikofficial@gmail.com | +491783576366 | Ilmenau, Deutschland | <a href="https://www.linkedin.com/in/zohaibmalikofficial/" target="_blank" style="color: #0061a8; text-decoration: none;">linkedin.com/in/zohaibmalikofficial</a>
            </div>
        </div>

        <div class="section">
            <div class="section-title">Berufliches Profil</div>
            <p style="font-size: 10px; color: #4a5568; text-align: justify;">
                Highly motivated and detail-oriented Working Student with experience in project support, data analysis, and presentations.  Proficient in <span class="azure-highlight">Python</span>, <span class="highlight">SQL</span>, and MS Office Suite (especially <span class="highlight">PowerPoint</span> and <span class="highlight">Excel</span>), seeking to support the Chief of Staff to the CTO at Statista.  Currently pursuing a Master's degree in Computer and Systems Engineering at TU Ilmenau, focusing on Cloud Computing and System Security. Eager to learn in a fast-paced environment and contribute to strategic initiatives within the Tech Office. Experience with collaboration tools like Jira and Confluence.
            </p>
        </div>

        <div class="section">
            <div class="section-title">Technische Kompetenzen</div>
            <div class="skills-grid">
                <div>
                    <div class="skill-category">
                        <div class="skill-category-title">Data Engineering & ETL:</div>
                        <div class="skill-list"><span class="azure-highlight">Azure Databricks, Apache Spark (PySpark)</span>, ETL/ELT-Pipelines, Data Factory, Airflow, <span class="azure-highlight">Kimball Datenmodellierung</span>, Data Vault (Grundlagen)</div>
                    </div>
                    <div class="skill-category">
                        <div class="skill-category-title">Programmierung & Scripting:</div>
                        <div class="skill-list">Python (Fortgeschritten), <span class="azure-highlight">Scala (Grundlagen)</span>, SQL (Fortgeschritten), pandas, PySpark, pytest, Flask</div>
                    </div>
                    <div class="skill-category">
                        <div class="skill-category-title">Cloud & Azure Services:</div>
                        <div class="skill-list"><span class="azure-highlight">Azure Data Lake Storage, Azure SQL Database, Azure Synapse Analytics</span>, AWS (Übertragbar), Kubernetes, Docker</div>
                    </div>
                </div>
                <div>
                    <div class="skill-category">
                        <div class="skill-category-title">Datenbanken & Storage:</div>
                        <div class="skill-list">PostgreSQL, MySQL, <span class="azure-highlight">Azure SQL, Delta Lake</span>, Data Warehouse Design, Datenbankoptimierung, NoSQL (MongoDB)</div>
                    </div>
                    <div class="skill-category">
                        <div class="skill-category-title">Datenqualität & Monitoring:</div>
                        <div class="skill-list">Data Quality Frameworks, <span class="azure-highlight">Azure Monitor</span>, Datenvalidierung, Fehlerbehandlung, Performance-Tuning</div>
                    </div>
                    <div class="skill-category">
                        <div class="skill-category-title">Agile & Kollaboration:</div>
                        <div class="skill-list">Git, CI/CD, <span class="azure-highlight">Agile Methoden</span>, Stakeholder-Kommunikation, Technische Dokumentation, Deutsch (A2+→B1)</div>
                    </div>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="section-title">Zentrale Data Engineering Projekte</div>
            <div class="projects-grid">
                <div class="project">
                    <div class="project-title">Azure Databricks ETL-Pipeline für Retail-Analytics mit Kimball Dimensional Modeling</div>
                    <div class="project-tech">Azure Databricks, PySpark, Azure Data Lake Storage Gen2, Delta Lake, Azure SQL Database, Python</div>
                    <div class="project-desc">Entwicklung einer skalierbaren ETL-Pipeline zur täglichen Verarbeitung von Verkaufsdaten, Lagerbeständen und Kundendaten aus 8 verschiedenen Quellsystemen (APIs, CSV, JSON, Datenbanken). Implementierung von <strong>Kimball Star-Schema</strong> mit 3 Fact-Tables (Sales, Inventory, Returns) und 7 Dimension-Tables. <strong>Optimierungstechniken:</strong> Delta Lake für ACID-Transaktionen, Partitionierung nach Datum/Region, Z-Ordering für bessere Query-Performance. <strong>Ergebnis:</strong> 65% schnellere Abfragezeiten durch optimierte Tabellenstrukturen, 99.7% Datenqualität durch implementierte Validierungsregeln, Reduzierung der Pipeline-Laufzeit von 4h auf 45min durch Parallelisierung.</div>
                </div>
                
                <div class="project">
                    <div class="project-title">Data Lakehouse Architektur mit Bronze-Silver-Gold Medallion Pattern</div>
                    <div class="project-tech">Azure Data Factory, PySpark, Delta Lake, Azure Synapse Analytics, Apache Airflow, SQL</div>
                    <div class="project-desc">Design und Aufbau einer mehrstufigen Data-Lakehouse-Architektur nach Medallion-Pattern für E-Commerce-Daten: <strong>Bronze</strong> (Raw Data Ingestion), <strong>Silver</strong> (Cleansed & Validated), <strong>Gold</strong> (Business-Ready Analytics). Implementierung automatisierter ELT-Prozesse mit Azure Data Factory für 12 verschiedene Datenquellen. <strong>Datenqualitätstechniken:</strong> Schema-Validierung, Duplikaterkennung, referentielle Integrität, automatische Anomalie-Detection. <strong>Ergebnis:</strong> Zentrale Datenverfügbarkeit für 25+ Analytics-Teams, 80% Reduzierung der Datenbereitstellungszeit von 6h auf 1h, Self-Service Analytics für Business-User.</div>
                </div>
                
                <div class="project">
                    <div class="project-title">Multi-Source Data Integration mit Data Vault 2.0 Modellierung</div>
                    <div class="project-tech">Azure Data Factory, SQL Server, Python, Azure SQL Database, Data Vault 2.0, PowerBI</div>
                    <div class="project-desc">Integration heterogener Unternehmensdaten aus ERP-Systemen, CRM-Datenbanken und Excel-Dateien unter Verwendung von <strong>Data Vault 2.0 Methodik</strong>. Aufbau von Hubs (Geschäftsentitäten), Links (Beziehungen) und Satellites (Kontextdaten) für historische Datenaufbewahrung und Audit-Compliance. <strong>ETL-Optimierungen:</strong> Incremental Loading, Change Data Capture (CDC), parallelisierte Batch-Jobs. <strong>Performance-Tuning:</strong> Indexstrategien, Query-Optimierung, Partitionierung. <strong>Ergebnis:</strong> 100% Datenrückverfolgbarkeit für Compliance-Anforderungen, 70% Verbesserung der Reportinggenauigkeit, Reduzierung manueller Datenabgleiche von 16h/Woche auf 2h/Woche.</div>
                </div>
                
                <div class="project">
                    <div class="project-title">Automatisierte ETL-Pipeline mit Datenqualitäts-Monitoring</div>
                    <div class="project-tech">Apache Spark, Python, PostgreSQL, Apache Airflow, Great Expectations, Grafana</div>
                    <div class="project-desc">Entwicklung einer robusten ETL-Pipeline zur Verarbeitung von Transaktionsdaten aus Online-Payment-Systemen mit integriertem Datenqualitäts-Framework. Implementierung von <strong>Great Expectations</strong> für automatisierte Datenvalidierung, Schema-Evolution-Handling und statistische Anomalie-Detection. <strong>Monitoring & Alerting:</strong> Grafana-Dashboards für Pipeline-Performance, Slack-Integration für Fehler-Benachrichtigungen, automatische Wiederanlauf-Mechanismen. <strong>Skalierungstechniken:</strong> Spark-Cluster-Optimierung, Memory-Management, broadcast joins für kleine Lookup-Tabellen. <strong>Ergebnis:</strong> 99.5% Pipeline-Verfügbarkeit, 90% Reduzierung manueller Datenvalidierung, automatische Behandlung von 95% der auftretenden Datenqualitätsprobleme.</div>
                </div>

                <div class="project">
                    <div class="project-title">Kubernetes-basierte Microservices Data Processing Platform</div>
                    <div class="project-tech">Kubernetes, Docker, Python Flask, Apache Kafka, Redis, PostgreSQL, Prometheus</div>
                    <div class="project-desc">Co-Entwicklung einer containerisierten Datenverarbeitungsplattform mit Custom Pod Autoscaler (CPA) für dynamische Skalierung basierend auf p95-Latenz-Metriken aus Prometheus. Design von 6 Microservices für verschiedene ETL-Aufgaben: Data Ingestion, Validation, Transformation, Quality Checks, und Output Generation. <strong>DevOps-Techniken:</strong> GitOps mit ArgoCD, CI/CD-Pipelines, Infrastructure as Code (YAML), Service Mesh für Inter-Service-Kommunikation. <strong>Monitoring & Observability:</strong> Prometheus Metrics, Grafana Dashboards, distributed Tracing. <strong>Ergebnis:</strong> Horizontale Skalierung von 2-50 Pods je nach Last, 40% bessere Resource-Utilization im Vergleich zu CPU-basiertem HPA, 99.9% Service-Verfügbarkeit.</div>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="section-title">Berufserfahrung</div>
            
            <div class="job">
                <div class="job-header">
                    <div>
                        <div class="job-title">Data Engineer / WordPress Developer</div>
                        <div class="company">FixRunner</div>
                        <div class="location">USA (Remote)</div>
                    </div>
                    <div class="job-period">Nov 2021 - Apr 2025</div>
                </div>
                <ul class="achievements">
                    <li>Developed and optimized data processing workflows using PHP, Javascript and Python to enhance website functionality for clients.</li>
                    <li>Collaborated remotely with global teams utilizing project management tools like Git, GitHub, and Asana to ensure efficient project delivery.</li>
                    <li>Diagnosed and resolved website errors, plugin conflicts, and security vulnerabilities across numerous projects, contributing to improved website functionality and security.</li>
                    <li>Documented technical implementations and communicated effectively with stakeholders to ensure clarity and transparency.</li>
                    <li>Integrated third-party APIs and implemented automation workflows to streamline project processes and increase efficiency.</li>

                </ul>
            </div>
        </div>

        <div class="section">
            <div class="section-title">Ausbildung</div>
            
            <div class="education-item">
                <div class="degree">Master of Research in Computer and Systems Engineering</div>
                <div class="university">Technische Universität Ilmenau (TU Ilmenau)</div>
                <div class="edu-details">
                    Ilmenau, Deutschland | Okt 2024 - Laufend <br>
                    <strong>Aktuelle Kurse:</strong> <span class="azure-highlight">Cloud Computing, Software Safety, System Security</span>, Advanced Algorithms, Mobile Communication Networks<br>
                    <strong>Relevanter Fokus:</strong> <span class="azure-highlight">Distributed Data Systems, Cloud-Architekturen, Sicherheit in der Datenverarbeitung</span>, DevOps-Methoden, Enterprise Software
                </div>
            </div>
            
            <div class="education-item">
                <div class="degree">Bachelor of Science in Computer Science</div>
                <div class="university">COMSATS University Islamabad</div>
                <div class="edu-details">
                    Pakistan | Feb 2019 - Feb 2023 <br>
                    <strong>Kernfächer:</strong> Datenstrukturen, Algorithmen, <span class="azure-highlight">Datenbankmanagement, Data Mining</span>, Software Engineering<br>
                    <strong>Abschlussprojekt:</strong> "Scalable Data Processing System" - Implementierung eines verteilten Datenverarbeitungssystems mit Apache Spark
                </div>
            </div>
        </div>

        <div class="section">
            <div class="section-title">Zertifizierungen & Weiterbildung</div>
            <div class="certifications">
                <div>
                    <div class="skill-category-title">Azure & Data Engineering:</div>
                    <div style="color: #4a5568;">
                        • <span class="azure-highlight">Azure Data Fundamentals (DP-900) - In Vorbereitung</span><br>
                        • Certified Data Engineer Associate<br>
                    </div>
                </div>
                <div>
                    <div class="skill-category-title">Technische Spezialisierungen:</div>
                    <div style="color: #4a5568;">
                        • ETL/ELT Pipeline Development<br>
                        • Advanced SQL für Data Warehousing<br>
                        • Python for Data Engineering<br>
                        • Cloud Data Architecture Patterns<br>
                        • Agile Data Engineering Methoden
                    </div>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="section-title">Zusätzliche Qualifikationen</div>
            
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; font-size: 10px;">
                <div>
                    <div class="skill-category-title">Sprachkenntnisse & Kommunikation:</div>
                    <div class="languages" style="flex-direction: column; gap: 5px;">
                        <span><strong>Deutsch:</strong> A2+ (Aktiv in B1-Kurs, Ziel: B2 bis Ende 2025)</span>
                        <span><strong>Englisch:</strong> Fließend (Technisch & Geschäftlich)</span>
                        <span><strong>Stakeholder-Kommunikation:</strong> Erfahrung mit interdisziplinären Teams und technischer Dokumentation</span>
                    </div>
                </div>
                <div>
                    <div class="skill-category-title">Verfügbarkeit & Bereitschaft:</div>
                    <div>
                        <strong>Status:</strong> Autorisierte Arbeitserlaubnis in Deutschland<br>
                        <strong>Startdatum:</strong> Oktober 2025 (flexibel)<br>
                        <strong>Lernbereitschaft:</strong> Kontinuierliche Weiterbildung in Azure-Technologien<br>
                        <strong>Teamarbeit:</strong> Agile Arbeitsweise, selbstorganisiert, proaktiv
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        function printResume() {
            window.print();
        }
        
        function addDownloadButton() {
            const button = document.createElement('button');
            button.textContent = '📄 Lebenslauf als PDF herunterladen';
            button.className = 'download-btn';
            button.style.cssText = `
                position: fixed;
                top: 20px;
                right: 20px;
                background: #0061a8;
                color: white;
                border: none;
                padding: 12px 24px;
                border-radius: 8px;
                cursor: pointer;
                font-size: 14px;
                font-weight: bold;
                z-index: 1000;
                box-shadow: 0 4px 12px rgba(0,0,0,0.15);
                transition: all 0.3s ease;
            `;
            button.onmouseover = () => button.style.background = '#004d87';
            button.onmouseout = () => button.style.background = '#0061a8';
            button.onclick = printResume;
            document.body.appendChild(button);
        }
        
        window.onload = addDownloadButton;
    </script>
</body>
</html>
